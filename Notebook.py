# -*- coding: utf-8 -*-
"""Jevon - Airbnb: Recommendation System

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fp64atSVaWpZBxF0F8gTfoKYUYezYwLM

Recommendation System based on Weighted Rating , Content and Clustering Model for AirBnB
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

!pip install gdown
import gdown

file_id = '1PJThBkaga0LXg-ferYLYKREN4sF9UxyR'
gdrive_url = f'https://drive.google.com/uc?id={file_id}'

# Download the file
output = 'airbnb.csv'
gdown.download(gdrive_url, output, quiet=False)

# Read the CSV file into a DataFrame
df = pd.read_csv(output)

pd.set_option('display.max_columns', None)

df.head()

"""### Dataset content :

1.  id: Unique identifier for each listing
2.  name: Name of the Airbnb listing
3.  rating: Average rating of the listing
4.   reviews: Number of reviews received
5.   host_name: Name of the host
6.   host_id: Unique identifier for the host
7.   address: Location of the listing (city, region, country)
8.  features: Summary of features (number of guests, bedrooms, beds, bathrooms)
9.  amenities: List of amenities provided
10. safety_rules
11. house_rules
12.  price: Price per month
13.  country: Country where the listing is located
14.  bathrooms: Number of bathrooms
15.  beds: Number of beds
16.  guests: Number of guests the listing can accommodate
17.  toilets: Number of toilets
18.  bedrooms: Number of bedrooms
19.  studios: Number of studio units
20.  checkin: Check-in time
21.  checkout: Check-out time

"""

df.info()

# Renaming the column
df.rename(columns={'hourse_rules': 'house_rules'}, inplace=True)
df.rename(columns={'toiles': 'toilets'}, inplace=True)

#replace new rating as 0
df['rating'] = df['rating'].replace('New', 0)

df['rating'] = df['rating'].astype(float)
df['reviews'] = df['reviews'].str.replace(',', '')
df['reviews'] = df['reviews'].astype(int)

df['rating'] = df['rating'].astype(int)

# Replace NaN values with 0 in the 'rating' column
df['rating'] = df['rating'].fillna(0)

# Remove leading and trailing whitespace in the 'country' column
df['country'] = df['country'].str.strip()

"""## Data Preprocessing"""

# Drop unnecessary columns
columns_to_drop = ['Unnamed: 0', 'img_links', 'features', 'address']
df.drop(columns=columns_to_drop, inplace=True, errors='ignore')

# Calculating the percentage of missing values for each column
missing_data = df.isnull().sum()
missing_percentage = (missing_data[missing_data > 0] / df.shape[0]) * 100

# Prepare values
missing_percentage.sort_values(ascending=True, inplace=True)

# Plot the barh chart
fig, ax = plt.subplots(figsize=(15, 4))
ax.barh(missing_percentage.index, missing_percentage, color='#ff6200')

# Annotate the values and indexes
for i, (value, name) in enumerate(zip(missing_percentage, missing_percentage.index)):
    ax.text(value+0.5, i, f"{value:.2f}%", ha='left', va='center', fontweight='bold', fontsize=18, color='black')

# Set x-axis limit
ax.set_xlim([0, 40])

# Add title and xlabel
plt.title("Percentage of Missing Values", fontweight='bold', fontsize=22)
plt.xlabel('Percentages (%)', fontsize=16)
plt.show()

# Replace missing values in 'checkin' and 'checkout' columns with 'Not specified'
df['checkin'].fillna('Not specified', inplace=True)
df['checkout'].fillna('Not specified', inplace=True)

# Check if there are any remaining missing values
missing_values = df.isnull().sum()
print("Missing values:\n", missing_values)

#create a copy after data cleaning
df_clean = df.copy()

#create price for one night
df['price_fix'] = df['price']/30
df['price_fix'] = df['price_fix'].round(2)

df = df.drop('price', axis=1)

# Check if there are any remaining missing values
missing_values = df.isnull().sum()
print("Missing values:\n", missing_values)

df.head()

"""## Exploratory Data Analysis

## Rating and Review Analysis
"""

# Calculate the percentage for each rating
rating_counts = df['rating'].value_counts().sort_index()
total_counts = rating_counts.sum()
percentages = (rating_counts / total_counts) * 100

plt.figure(figsize=(10, 6))

# Use the Blues_r color palette and a horizontal bar plot
ax = sns.countplot(data=df, y='rating', palette='Blues_r', order=rating_counts.index)

# Adding value labels with both frequency and percentage
for patch in ax.patches:
    width = patch.get_width()  # Frequency value (height of the bar)
    y = patch.get_y() + patch.get_height() / 2  # Midpoint of the bar's height

    # Extract the rating value from the y-axis index
    rating = patch.get_y() + patch.get_height() / 2
    percentage = percentages.get(rating_counts.index[int(rating)], 0)

    label_text = f'{int(width)} ({percentage:.1f}%)'

    # Add label text with position adjusted
    ax.text(width + 0.2, y, label_text, ha='left', va='center', color='black', fontsize=10)

plt.title('Distribution of Ratings', fontsize=16)
plt.xlabel('Frequency', fontsize=14)
plt.ylabel('Rating', fontsize=14)
plt.grid(axis='x', alpha=0.75)

# Ensure layout adjusts to avoid overlapping elements
plt.tight_layout()

plt.show()

# Create box plot
plt.figure(figsize=(12, 8))
sns.boxplot(data=df, x='rating', y='reviews', palette='Blues_r')

# Setting the style to minimalist
sns.set(style="whitegrid")

# title and labels
plt.title('Distribution of Reviews by Rating', fontsize=16)
plt.xlabel('Rating', fontsize=14)
plt.ylabel('Number of Reviews', fontsize=14)

# Removing gridlines except for y-axis for subtle guidance
plt.grid(True, axis='y', linestyle='--', alpha=0.5)

# Customizing ticks and spines for a clean look
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

# Ensuring layout is tight and doesn't overlap
plt.tight_layout()

plt.show()

"""## Price Analysis"""

# Box plot for price distribution
plt.figure(figsize=(12, 8))
sns.boxplot(data=df, x='price_fix', color='#1f77b4')  # Classy blue color

# Setting the style to minimalist
sns.set(style="whitegrid")

# Minimalist title and labels
plt.title('Price Distribution', fontsize=16)
plt.xlabel('Price', fontsize=14)

# Removing gridlines except for y-axis for subtle guidance
plt.grid(True, axis='y', linestyle='--', alpha=0.5)

# Customizing ticks and spines for a clean look
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

# Ensuring layout is tight and doesn't overlap
plt.tight_layout()

plt.show()

# Calculate the specific percentiles for the price_fix column
percentiles = df['price_fix'].quantile([0.25, 0.5, 0.75, 0.9])

# Create a DataFrame for these specific percentiles
percentile_df = pd.DataFrame(percentiles, columns=['price_fix']).reset_index()
percentile_df.columns = ['Percentile', 'price_fix']
percentile_df['Percentile'] = ['25%', '50%', '75%', '90%']

# Plot the percentiles
plt.figure(figsize=(10, 6))
barplot = sns.barplot(x='Percentile', y='price_fix', data=percentile_df, palette='Blues')

# Setting the style to minimalist
sns.set(style="whitegrid")

# Minimalist title and labels
plt.title('Price Distribution at 25%, 50%, 75%, and 90% Percentiles', fontsize=16)
plt.xlabel('Percentile', fontsize=14)
plt.ylabel('Price', fontsize=14)

# Removing gridlines except for y-axis for subtle guidance
plt.grid(True, axis='y', linestyle='--', alpha=0.5)

# Add labels on the bars
for index, row in percentile_df.iterrows():
    barplot.text(index, row['price_fix'], f'{row["price_fix"]:.0f}', color='black', ha="center", va="bottom")

# Customizing ticks and spines for a clean look
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
plt.gca().spines['top'].set_visible(False)
plt.gca().spines['right'].set_visible(False)

# Ensuring layout is tight and doesn't overlap
plt.tight_layout()

plt.show()

"""## Price Impact to Rating, Reviews and Number of Beds"""

# Create a scatter plot to show the relationship between reviews and price_fix
plt.figure(figsize=(10, 6))
sns.scatterplot(x='price_fix', y='rating', data=df)
plt.title('Rating vs. Adjusted Price per Night')
plt.xlabel('Adjusted Price per Night')
plt.ylabel('Reviews')
plt.show()

# Create a scatter plot to show the relationship between reviews and price_fix
plt.figure(figsize=(10, 6))
sns.scatterplot(x='price_fix', y='reviews', data=df)
plt.title('Reviews vs. Adjusted Price per Night')
plt.xlabel('Adjusted Price per Night')
plt.ylabel('Reviews')
plt.show()

# Scatter plot with 'beds' on the x-axis, 'price_fix' on the y-axis, and color by 'rating'
plt.figure(figsize=(12, 8))
scatter_plot = sns.scatterplot(data=df, x='beds', y='price_fix', hue='rating', palette='Blues_d', s=100, alpha=0.8)

# Set title and labels
plt.title('Scatter Plot of Beds vs. Price, Colored by Rating', fontsize=16)
plt.xlabel('Number of Beds', fontsize=14)
plt.ylabel('Price Fix', fontsize=14)

# Customize legend and layout for a professional look
plt.legend(title='Rating', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, linestyle='--', alpha=0.5)

# Ensure layout is tight and visually appealing
plt.tight_layout()

# Display the plot
plt.show()

"""## Countries Analysis"""

top_countries = df['country'].value_counts().index[:10]
top_counts = df['country'].value_counts().loc[top_countries]
total_listings = df['country'].count()
top_percentages = (top_counts / total_listings * 100).round(2)

plt.figure(figsize=(12, 8))
ax = sns.countplot(x='country', data=df, order=top_countries)

# Add labels and percentages to each bar
for p in ax.patches:
    country = p.get_x() + p.get_width() / 2
    count = p.get_height()
    percentage = top_percentages.loc[df['country'].value_counts().index[int(country)]]
    label = f'{count}\n({percentage}%)'
    ax.annotate(label,
                (p.get_x() + p.get_width() / 2., p.get_height()),
                ha='center', va='center',
                xytext=(0, 9),  # 9 points vertical offset
                textcoords='offset points')

plt.title('Top 10 Countries with Airbnb Listings')
plt.xlabel('Country')
plt.ylabel('Number of Listings')
plt.xticks(rotation=45)
plt.show()

"""## EDA"""

# Calculate the total number of reviews for each country
country_review_counts = df.groupby('country')['reviews'].sum().sort_values(ascending=False)

# Get the top countries by total number of reviews
top_countries_by_reviews = country_review_counts.head(10)

# Create a horizontal bar chart for the most reviewed countries
plt.figure(figsize=(12, 8))
ax = sns.barplot(y=top_countries_by_reviews.index, x=top_countries_by_reviews.values, palette='viridis')

# Add percentage labels on the right side of each bar
total_reviews = top_countries_by_reviews.sum()
for i, v in enumerate(top_countries_by_reviews.values):
    percentage = f'{(v / total_reviews) * 100:.1f}%'
    ax.text(v + 5, i, f'{v} ({percentage})', color='black', va='center')

plt.title('Top 10 Most Reviewed Countries')
plt.ylabel('Country')
plt.xlabel('Total Number of Reviews')
plt.grid(True, axis='x')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Group by country and calculate the average rating
country_ratings = df.groupby('country')['rating'].mean().reset_index()

# Sort the countries by average rating in descending order
top_countries = country_ratings.sort_values(by='rating', ascending=False).head(10)

# Plot the top 10 countries with the highest average ratings
plt.figure(figsize=(12, 8))
ax = sns.barplot(x='rating', y='country', data=top_countries, palette='viridis')

# Add labels to each bar
for p in ax.patches:
    width = p.get_width()
    ax.annotate(f'{width:.2f}', (width + 0.02, p.get_y() + p.get_height() / 2),
                ha='center', va='center', fontsize=10, color='black')

plt.title('Top 10 Countries by Average Rating')
plt.xlabel('Average Rating')
plt.ylabel('Country')
plt.show()

# Calculate the average price per night by country
avg_price_by_country = df.groupby('country')['price_fix'].median().sort_values(ascending=False)

# Get top 10 countries by average price
top_countries = avg_price_by_country.head(10).index

# Filter DataFrame to include only top 10 countries
df_top_countries = df[df['country'].isin(top_countries)]

# Calculate the total price for the top 10 countries
total_price = avg_price_by_country[top_countries].sum()

# Normalize prices for color intensity
normalized_prices = (avg_price_by_country[top_countries].values - avg_price_by_country[top_countries].values.min()) / (avg_price_by_country[top_countries].values.max() - avg_price_by_country[top_countries].values.min())

# Generate color intensities based on normalized prices
colors = sns.color_palette('Blues', n_colors=10)
color_map = [colors[int(val * 9)] for val in normalized_prices]

# Horizontal bar chart of average price per night by country (top 10 by average price)
plt.figure(figsize=(12, 8))
ax = sns.barplot(y=avg_price_by_country[top_countries].index, x=avg_price_by_country[top_countries].values, palette=color_map)

# Add labels to each bar with both price and percentage
for p in ax.patches:
    price = p.get_width()
    percentage = (price / total_price) * 100
    ax.annotate(f'{price:.2f} ({percentage:.1f}%)',
                (p.get_width(), p.get_y() + p.get_height() / 2),
                ha='left', va='center',
                xytext=(5, 0),  # 5 points horizontal offset
                textcoords='offset points',
                color='black')  # Label color

# Add title and labels
plt.title('Top 10 Countries by Average Price per Night', fontsize = 16)
plt.ylabel('Country')
plt.xlabel('Average Price per Night')

# Add grid for x-axis
plt.grid(True, axis='x', linestyle='--', alpha=0.5)

# Display the plot
plt.show()

# Calculate average rating and total reviews for each listing
listing_avg_rating = df.groupby('name')['rating'].mean()
listing_total_reviews = df.groupby('name')['reviews'].sum()

# Combine into a single DataFrame and sort by total reviews
listing_summary = pd.DataFrame({
    'Average Rating': listing_avg_rating,
    'Total Reviews': listing_total_reviews
}).sort_values(by='Total Reviews', ascending=False)

# Get the top 10 listings by total reviews
top_10_listings = listing_summary.head(10)

# Filter the original DataFrame to include only top 10 listings
df_top_10_listings = df[df['name'].isin(top_10_listings.index)]

# Extract country, host name, and median price for top 10 listings
top_10_countries = df_top_10_listings.groupby('name')['country'].first()
top_10_host_names = df_top_10_listings.groupby('name')['host_name'].first()
top_10_prices = df_top_10_listings.groupby('name')['price_fix'].median()

# Combine all details into a final DataFrame
top_10_final_summary = pd.DataFrame({
    'Listing Name': top_10_listings.index,
    'Host Name': top_10_host_names.values,
    'Average Rating': top_10_listings['Average Rating'],
    'Total Reviews': top_10_listings['Total Reviews'],
    'Country': top_10_countries.values,
    'Median Price ($)': top_10_prices.values
}).reset_index(drop=True)

# Display the DataFrame
top_10_final_summary

"""## Analysis by Listings"""

# Set the figure size and style
plt.figure(figsize=(14, 8))
sns.set(style="whitegrid")

# Create a new figure and axes
fig, ax1 = plt.subplots(figsize=(14, 8))

# Horizontal bar plot
sns.barplot(x='Total Reviews', y='Listing Name', data=top_10_final_summary, palette='viridis', ax=ax1)

# Adding labels and titles
ax1.set_title('Top 10 Listings by Total Reviews')
ax1.set_xlabel('Total Reviews')
ax1.set_ylabel('Listing Name')

# Adding labels to each bar
for index, value in enumerate(top_10_final_summary['Total Reviews']):
    ax1.text(value, index, f'{value:,}', va='center', ha='left', color='black')

# Adding a legend
ax1.legend(['Total Reviews'], loc='upper left')

# Show the plot
plt.show()

# Filter the top 10 listings data
df_top_10_scatter = df[df['name'].isin(top_10_listings.index)]

# Scatter plot with 'beds' on the x-axis, 'price_fix' on the y-axis, and color by 'rating'
plt.figure(figsize=(12, 8))
scatter_plot = sns.scatterplot(data=df_top_10_scatter, x='beds', y='price_fix', hue='rating', palette='Blues_d', s=100, alpha=0.8)

# Set title and labels
plt.title('Top 10 Reviewed Listings: Number of Beds vs Price (Colored by Rating)', fontsize=16)
plt.xlabel('Number of Beds', fontsize=14)
plt.ylabel('Price Fix', fontsize=14)

# Customize legend and layout for a professional look
plt.legend(title='Rating', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, linestyle='--', alpha=0.5)

# Ensure layout is tight and visually appealing
plt.tight_layout()

# Display the plot
plt.show()

# Filter out listings with rating <= 0 or reviews <= 0
filtered_df = df[(df['rating'] > 0) & (df['reviews'] > 0)]

# Sort by price in descending order
sorted_df = filtered_df.sort_values(by='price_fix', ascending=False)

# Select the top 10 listings
top_10_price_listings = sorted_df[['name', 'price_fix', 'rating', 'reviews', 'country']].head(10)

# Reset index for better readability
top_10_price_listings = top_10_price_listings.reset_index(drop=True)

# Display the DataFrame with the top 10 listings
top_10_price_listings

# Set the figure size and style
plt.figure(figsize=(14, 8))
sns.set(style="whitegrid")

# Create a horizontal bar plot for price
ax = sns.barplot(x='price_fix', y='name', data=top_10_price_listings, palette='viridis')

# Add labels and title
plt.title('Top 10 Listings by Price')
plt.xlabel('Price ($)')
plt.ylabel('Listing Name')

# Add value labels on each bar
for container in ax.containers:
    ax.bar_label(container, fmt='${:.2f}', label_type='edge', color='black')

# Show the plot
plt.show()

# Filter the top 10 listings data
df_top_10_price = df[df['name'].isin(top_10_price_listings['name'])]

# Scatter plot with 'beds' on the x-axis, 'price_fix' on the y-axis, and color by 'rating'
plt.figure(figsize=(12, 8))
scatter_plot = sns.scatterplot(data=df_top_10_price, x='beds', y='reviews', hue='rating', palette='Blues_d', s=100, alpha=0.8)

# Set title and labels
plt.title('Top 10 High Price Listings: Number of Reviews vs Price (Colored by Rating)', fontsize=16)
plt.xlabel('Number of beds', fontsize=14)
plt.ylabel('Reviews', fontsize=14)

# Customize legend and layout for a professional look
plt.legend(title='Rating', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.grid(True, linestyle='--', alpha=0.5)

# Ensure layout is tight and visually appealing
plt.tight_layout()

# Display the plot
plt.show()

"""## Weighted Rating Recommendation System"""

# Calculate C (mean rating across all listings)
C = df['rating'].mean()

# Calculate m (minimum number of reviews required to be listed)
m = df['reviews'].quantile(0.9)

# Filter listings that qualify (have reviews >= m)
q_listings = df.copy().loc[df['reviews'] >= m]
print(q_listings.shape)

# Define the weighted rating function
def weighted_rating(x, m=m, C=C):
    v = x['reviews']
    R = x['rating']
    return (v / (v + m) * R) + (m / (m + v) * C)

# Calculate the score for qualified listings
q_listings['score'] = q_listings.apply(weighted_rating, axis=1)

# Sort listings by score
q_listings = q_listings.sort_values('score', ascending=False)

country_input = input('Enter country:').strip().lower()

min_price = int(input('Enter minimum price:'))

max_price = int(input('Enter maximum price:'))

# Filter DataFrame based on inputs
filtered_listings = q_listings[q_listings['country'].str.lower() == country_input]
filtered_listings = filtered_listings[(filtered_listings['price_fix'] >= min_price) & (filtered_listings['price_fix'] <= max_price)]

top_listings = filtered_listings[['name', 'reviews', 'rating', 'score', 'price_fix', 'country']].head(10)
top_listings

"""## Content Based Filtering"""

# Function to convert all strings to lower case and strip names of spaces
def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        #Check if director exists. If not, return empty string
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

# Apply clean_data function to your features.
features = ['amenities', 'country']

for feature in features:
    df[feature] = df[feature].apply(clean_data)

def create_soup(x):
    return ' '.join(x['amenities']) + ' ' + x['country']
df['soup'] = df.apply(create_soup, axis=1)

# Import CountVectorizer and create the count matrix
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(df['soup'])

# Compute the Cosine Similarity matrix based on the count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(count_matrix, count_matrix)

indices = pd.Series(df.index, index=df['name'])

def get_recommendations(names, cosine_sim=cosine_sim):
    recommendations = pd.DataFrame()
    for name in names:
        if name in indices.index:
            # Get the index of the listing that matches the name
            idx = indices[name]

            # Get the pairwise similarity scores of all listings with that listing
            sim_scores = list(enumerate(cosine_sim[idx]))

            # Sort the listings based on the similarity scores
            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

            # Get the scores of the top 10 most similar listings
            sim_scores = sim_scores[1:11]

            # Get the listing indices
            listing_indices = [i[0] for i in sim_scores]

            # Retrieve the relevant listings with their details
            recommended_listings = df.iloc[listing_indices][['name', 'rating', 'amenities','country']]

            ##recommended_listings = recommended_listings[(recommended_listings['rating'] > 0) & (recommended_listings['country'] == country_filter)]

            #Filter out listings with a rating of zero
            recommended_listings = recommended_listings[(recommended_listings['rating'] > 0)]

            return recommended_listings

#create sample as user bookings history
n = 10

# Randomly select n rows from df to create df_sample
df_sample = df.sample(n=n, random_state=None).copy()

df_sample

df_sample['amenities'].value_counts().reset_index()

df_sample['country'].value_counts().reset_index()

# Example usage
recommendation_list = df_sample['name'].tolist()
recommendations = get_recommendations(recommendation_list)
recommendations

"""## FEATURE ENGINEERING FOR CLUSTERING"""

df_1 = df.copy()

df.head(10)

"""#Encoding checkin and checkout time"""

df['checkin'].unique()

import pandas as pd
import re


# Define a function to categorize check-in times
def categorize_checkin_time(time_str):
    time_str = time_str.strip()

    if time_str == 'Flexible':
        return 'Flexible'
    elif time_str == 'Not specified':
        return 'Not specified'

    # Extract hour from the time string
    match = re.search(r'(\d{1,2})\s*(am|pm)', time_str)
    if match:
        hour, period = int(match.group(1)), match.group(2)
        if period == 'pm' and hour != 12:
            hour += 12
        elif period == 'am' and hour == 12:
            hour = 0

        if hour < 9:
            return 'Early Morning'
        elif 9 <= hour < 12:
            return 'Morning'
        elif 12 <= hour < 15:
            return 'Early Afternoon'
        elif 15 <= hour < 18:
            return 'Afternoon'
        elif 18 <= hour < 21:
            return 'Evening'
        else:
            return 'Late Evening/Night'
    return 'Other'

# Apply the categorization function
df['checkin'] = df['checkin'].apply(categorize_checkin_time)

df['checkout'].unique()

# Define a function to categorize check-in times
def categorize_checkout_time(time_str):
    time_str = time_str.strip()

    if time_str == 'Not specified':
        return 'Not specified'

    # Extract hour and period (AM/PM) from the time string
    match = re.search(r'(\d{1,2})\s*(am|pm)', time_str)
    if match:
        hour, period = int(match.group(1)), match.group(2)
        if period == 'pm' and hour != 12:
            hour += 12
        elif period == 'am' and hour == 12:
            hour = 0

        # Categorize based on hour
        if hour < 9:
            return 'Early Morning'
        elif 9 <= hour < 12:
            return 'Morning'
        elif 12 <= hour < 17:
            return 'Afternoon'
        elif 17 <= hour < 21:
            return 'Evening'
        else:
            return 'Late Evening/Night'
    return 'Other'

# Apply the categorization function
df['checkout'] = df['checkout'].apply(categorize_checkin_time)

#final result of new group of check out time
df['checkout'].unique()

#final result of new group of check in time
df['checkin'].unique()

#encoding checkin and checkout time
checkin_encoding = {
    'Not specified': 0,
    'Early Morning': 1,
    'Early Afternoon': 2,
    'Flexible': 3,

}

checkout_encoding = {
    'Not specified': 0,
    'Early Morning': 1,
    'Early Afternoon': 2,
}

# Apply label encoding to the checkin and checkout columns
df['checkin'] = df['checkin'].map(checkin_encoding)
df['checkout'] = df['checkout'].map(checkout_encoding)

df_amenities = df.copy()

df = df_amenities

df.head()

df['amenities'].unique()

"""## Encoding Amenities"""

# Define simplified amenity groups with separate view types
simplified_amenities = {
    'Mountain view': ['mountainview'],
    'Valley view': ['valleyview'],
    'Lake access': ['lakeaccess'],
    'Sea view': ['seaview'],
    'Kitchen': ['kitchen'],
    'Wifi': ['wifi'],
    'Parking': ['freeparkingonpremises', 'freedrivewayparkingonpremises'],
    'Pets': ['petsallowed'],
    'Television': ['tv', '40"hdtvwithcable/satellitetv', 'tvwithstandardcable/satellite'],
    'Workspace': ['dedicatedworkspace'],
    'Pool': ['privatepool'],
    'Hot tub': ['privatehottub'],
    'Washer': ['washingmachine', 'freewasher–inbuilding'],
    'Air conditioning': ['airconditioning'],
    'Security': ['securitycamerasonproperty'],
    'Smoke alarm': ['Unavailable:smokealarmsmokealarm'],
    'Carbon monoxide alarm': ['unavailable:carbonmonoxidealarmcarbonmonoxidealarm'],
    'Garden': ['garden'],
    'Patio': ['privatepatioorbalcony'],
    'Breakfast': ['breakfast']
}

# Function to create binary columns for each simplified amenity
def create_binary_columns(df, amenities_dict):
    for key, values in amenities_dict.items():
        column_name = f'amenities_{key}'
        df[column_name] = df['amenities'].apply(lambda x: 1 if any(amenity in x for amenity in values) and not any(f'Unavailable: {amenity}' in x for amenity in values) else 0)
    return df

# Apply function
df = create_binary_columns(df, simplified_amenities)



df.head()

"""## Encoding house_rules and safety_rules"""

df['house_rules'].value_counts()

# Function to remove check-in and check-out times
def remove_check_in_out(rules):
    rules_list = rules.split(',')
    filtered_rules = [rule for rule in rules_list if not ('Check-in' in rule or 'Check out' in rule)]
    return ','.join(filtered_rules)

# Apply the function to remove check-in and check-out times
df['house_rules'] = df['house_rules'].apply(remove_check_in_out)

# Define the house rules to create binary columns
house_rules = [
    'Pets are allowed',
    'No pets',
    'Smoking is allowed',
    'No smoking',
    'No parties or events',
    'Self check-in with lockbox',
    'Not suitable for infants (under 2 years)'
]

# Function to create binary columns for each house rule
def create_house_rules_columns(df, rules_list):
    for rule in rules_list:
        column_name = f'house_{rule.lower().replace(" ", "_")}'
        df[column_name] = df['house_rules'].apply(lambda x: 1 if rule in x else 0)
    return df

# Apply the function to create binary columns
df = create_house_rules_columns(df, house_rules)

# Drop the original 'house_rules' column if needed
df = df.drop(columns=['house_rules'])

drop = ['house_no_pets', 'house_no_smoking']
df = df.drop(columns=drop)

df['safety_rules'].value_counts()

# Function to remove carbon monoxide and smoke alarms
def remove_alarms(rules):
    rules_list = rules.split(',')
    filtered_rules = [rule for rule in rules_list if 'carbon monoxide alarm' not in rule.lower() and 'smoke alarm' not in rule.lower()]
    return ','.join(filtered_rules)

# Apply the function to remove carbon monoxide and smoke alarms
df['safety_rules'] = df['safety_rules'].apply(remove_alarms)

# Define the safety rules to create binary columns with simplified names
safety_rules = {
    'safety_covid_practices': "Airbnb's COVID-19 safety practices apply",
    'safety_camera_device': 'Security camera/recording device',
    'safety_pool_hot_tub_no_gate': 'Pool/hot tub without a gate or lock',
    'safety_heights_no_protection': 'Heights without rails or protection',
    'safety_dangerous_animals': 'May encounter potentially dangerous animals'
}

# Function to create binary columns for each safety rule
def create_safety_rules_columns(df, rules_dict):
    for column, rule in rules_dict.items():
        column_name = f'safety_{rule.lower().replace(" ", "_")}'
        df[column] = df['safety_rules'].apply(lambda x: 1 if rule in x else 0)
    return df

# Apply the function to create binary columns
df = create_safety_rules_columns(df, safety_rules)

# Drop the original 'safety_rules' column if needed
df = df.drop(columns=['safety_rules'])

df.drop(columns=['safety_covid_practices'], inplace=True)

from sklearn.preprocessing import LabelEncoder

# Create a label encoder instance
label_encoder = LabelEncoder()

# Fit and transform the 'country' column
df['country_label'] = label_encoder.fit_transform(df['country'].str.strip())

df.head()

df.info()

"""## Create New Features"""

new_df = df.copy()

# Family Suitability: Enhanced with more features
df['family_suitability'] = (
    df['house_pets_are_allowed'] +
    df['house_smoking_is_allowed'] +
    df['house_no_parties_or_events'] +
    df['house_self_check-in_with_lockbox'] +
    df['house_not_suitable_for_infants_(under_2_years)']
)

# work suitability: Enhanced with more features
df['work_suitability'] = (
    df['amenities_Wifi'] +
    df['amenities_Workspace'] +
    df['amenities_Air conditioning']

)

# Price Range
#df['price_range'] = pd.cut(df['price_fix'], bins=[0, 50, 150, np.inf], labels=[1, 2, 3])
#df['price_range'] = df['price_range'].astype(int)

# Safety: Sum relevant features
df['safety'] = (
    df['safety_camera_device'] +
    df['safety_pool_hot_tub_no_gate'] +
    df['safety_heights_no_protection'] +
    df['safety_dangerous_animals'] +
    df['amenities_Security'] +
    df['amenities_Smoke alarm'] +
    df['amenities_Carbon monoxide alarm'] +
    df['house_self_check-in_with_lockbox']
)

# Natural Condition: Sum relevant amenities
df['natural_condition'] = (
    df['amenities_Mountain view'] +
    df['amenities_Valley view'] +
    df['amenities_Lake access'] +
    df['amenities_Sea view']
)

# Country Encoding (if needed, otherwise you can keep it as is)
df['country'] = df['country'].astype('category').cat.codes

# Create new DataFrame with selected features
new_df = df[['id', 'rating', 'reviews', 'bathrooms','beds',	'guests', 'toilets',	'bedrooms',	'studios'	,'checkin',	'checkout', 'host_id', 'country',
             'family_suitability', 'price_fix', 'safety', 'natural_condition',
             'work_suitability']]

new_df.head()

"""## EXPLORATORY DATA ANALYSIS FOR NEW FEATURES

"""

# Calculate the total number of reviews for each family suitability level
total_reviews_by_suitability = new_df.groupby('family_suitability')['reviews'].sum()

# Calculate the total number of reviews across all categories for percentage calculation
total_reviews = total_reviews_by_suitability.sum()

# Create the bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=total_reviews_by_suitability.index, y=total_reviews_by_suitability.values, palette='crest')

# Add labels with total values and percentages on each bar
for p in ax.patches:
    height = p.get_height()
    percentage = f'{(height / total_reviews) * 100:.1f}%'
    ax.annotate(f'{height:.0f} ({percentage})',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom',
                fontsize=10, color='black')

# Set title and labels
plt.title('Total Reviews by Family Suitability')
plt.xlabel('Family Suitability')
plt.ylabel('Total Reviews')

# Remove the small line from each bar
sns.despine(left=True, bottom=True)

# Show grid for better readability
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

# Calculate the total median price_fix across all categories
total_median_price_fix = new_df.groupby('family_suitability')['price_fix'].median().sum()

# Create the bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(data=new_df, x='family_suitability', y='price_fix', palette='crest', estimator=np.median, ci=None)

# Add labels with median values and percentages on each bar
for p in ax.patches:
    height = p.get_height()
    percentage = f'{(height / total_median_price_fix) * 100:.1f}%'
    ax.annotate(f'{height:.0f} ({percentage})',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom',
                fontsize=10, color='black')

# Set title and labels
plt.title('Price Distribution by Family Suitability')
plt.xlabel('Family Suitability')
plt.ylabel('Median Price Fix')

# Remove the small line from each bar
sns.despine(left=True, bottom=True)

# Show grid for better readability
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

# Calculate the total number of reviews for each safety level
total_reviews_by_safety = new_df.groupby('safety')['reviews'].sum()

# Calculate the total number of reviews across all categories for percentage calculation
total_reviews_safety = total_reviews_by_safety.sum()

# Create the bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=total_reviews_by_safety.index, y=total_reviews_by_safety.values, palette='crest')

# Add labels with total values and percentages on each bar
for p in ax.patches:
    height = p.get_height()
    percentage = f'{(height / total_reviews) * 100:.1f}%'
    ax.annotate(f'{height:.0f} ({percentage})',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom',
                fontsize=10, color='black')

# Set title and labels
plt.title('Total Reviews by Safety Features')
plt.xlabel('Safety Features')
plt.ylabel('Total Reviews')

# Remove the small line from each bar
sns.despine(left=True, bottom=True)

# Show grid for better readability
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

# Calculate the average rating by safety level
avg_rating_by_safety = new_df.groupby('safety')['rating'].mean()

# Create the bar plot
plt.figure(figsize=(10, 6))
ax = sns.barplot(x=avg_rating_by_safety.index, y=avg_rating_by_safety.values, palette='crest', ci=None)

# Add labels with average rating values on each bar
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height:.2f}',
                (p.get_x() + p.get_width() / 2., height),
                ha='center', va='bottom',
                fontsize=10, color='black')

# Set title and labels
plt.title('Average Rating by Safety Level')
plt.xlabel('Safety Features')
plt.ylabel('Average Rating')

# Remove the small line from each bar
sns.despine(left=True, bottom=True)

# Show grid for better readability
plt.grid(True, axis='y', linestyle='--', alpha=0.7)

# Display the plot
plt.tight_layout()
plt.show()

"""## Kmeans Clustering Recommendation System

## n_cluster tuning elbow method
"""

from sklearn.cluster import KMeans
from yellowbrick.cluster import KElbowVisualizer

# Set plot style, and background color
sns.set(style='darkgrid', rc={'axes.facecolor': '#fcf0dc'})

# Set the color palette for the plot
sns.set_palette(['#ff6200'])

# Instantiate the clustering model with the specified parameters
km = KMeans(init='k-means++', n_init=10, max_iter=100, random_state=0)

# Create a figure and axis with the desired size
fig, ax = plt.subplots(figsize=(12, 5))

# Instantiate the KElbowVisualizer with the model and range of k values, and disable the timing plot
visualizer = KElbowVisualizer(km, k=(2, 15), timings=False, ax=ax)


# Fit the data to the visualizer
visualizer.fit(new_df)

# Finalize and render the figure
visualizer.show();

"""## n_cluster tuning silhouette method"""

from sklearn.metrics import silhouette_score

range_n_clusters = list(range(2,11))
print(range_n_clusters)

arr_silhouette_score_euclidean = []
for i in range_n_clusters:
    kmeans = KMeans(n_clusters=i).fit(new_df)
    preds = kmeans.predict(new_df)

    score_euclidean = silhouette_score(new_df, preds, metric='euclidean')
    arr_silhouette_score_euclidean.append(score_euclidean)

fig, ax = plt.subplots(figsize=(8, 6))
sns.lineplot(x=range(2,11), y=arr_silhouette_score_euclidean, color='#000087', linewidth = 4)
sns.scatterplot(x=range(2,11), y=arr_silhouette_score_euclidean, s=300, color='#800000',  linestyle='--')

"""## Fit Kmeans Cluster Model and Create Cluster Plot"""

kmeans = KMeans(n_clusters=4, random_state=100).fit(new_df)
new_df['cluster'] = kmeans.labels_

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(new_df)
pcs = pca.transform(new_df)

pca = pd.DataFrame(data = pcs, columns = ['pc1', 'pc2'])
pca.head()

pca['cluster'] = kmeans.labels_

fig, ax = plt.subplots(figsize=(15,10))

sns.scatterplot(
    x="pc1", y="pc2",
    hue="cluster",
    edgecolor='white',
    linestyle='--',
    data=pca,
    palette=['#000087','#800000','#005f00',"#808000",'#808080'],
    s=160,
    ax=ax
)

# Define a custom mode function
def mode(series):
    return series.mode().iloc[0]

# Calculate the centroids for each cluster
centroid_df = new_df.groupby('cluster')[['rating', 'reviews', 'bathrooms', 'beds', 'guests', 'toilets',
                                         'bedrooms', 'studios', 'checkin', 'checkout',
                                         'family_suitability', 'price_fix', 'safety',
                                         'natural_condition', 'work_suitability', 'id']].agg({
    'rating': 'mean',
    'reviews': 'mean',
    'bathrooms': 'median',
    'beds': 'median',
    'guests': 'median',
    'toilets': 'median',
    'bedrooms': 'median',
    'studios': 'median',
    'checkin': mode,
    'checkout': mode,
    'family_suitability': mode,
    'price_fix': 'median',
    'safety': 'median',
    'natural_condition': mode,
    'work_suitability': mode,
    'id': 'nunique'
}).reset_index()

# Rename the 'id' column to 'num_listings'
centroid_df = centroid_df.rename(columns={'id': 'num_listings'})

centroid_df

"""## Apply K-Means Cluster Recommendation System"""

new_df.head()

n = 10

# Randomly select n rows from df to create df_sample
df_sample_1 = new_df.sample(n=n, random_state=None).copy()
df_sample_1.head(10)

#Identify the Top 10 Best-Rated Listings in Each Cluster
best_rated_listings = new_df.groupby(['cluster', 'id']).agg({'rating': 'mean', 'reviews': 'sum'}).reset_index()
best_rated_listings = best_rated_listings.sort_values(by=['cluster', 'rating', 'reviews'], ascending=[True, False, False])
top_listings_per_cluster = best_rated_listings.groupby('cluster').head(10)

#Generate Recommendations for Each Listing in df_sample_1
recommendations = []

for i, row in df_sample_1.iterrows():
    # Get the cluster of the current sample listing
    cluster = row['cluster']

    # Get the top listings in the same cluster
    top_listings = top_listings_per_cluster[top_listings_per_cluster['cluster'] == cluster]

    # Find top 3 listings in the best-rated list that are not the current listing
    top_listings_not_current = top_listings[top_listings['id'] != row['id']]
    top_3_listings_not_current = top_listings_not_current.head(3)

    # Append the recommendations to the list
    for _, rec_row in top_3_listings_not_current.iterrows():
        recommendations.append([row['id'], cluster, rec_row['id'], rec_row['rating']])

#Create a DataFrame from the Recommendations List
recommendations_df = pd.DataFrame(recommendations, columns=['source_id', 'cluster', 'rec_id', 'rec_rating'])
df_recommendations = df_sample_1.merge(recommendations_df, left_on=['id', 'cluster'], right_on=['source_id', 'cluster'], how='right')

df_recommendations_fix = df_recommendations.drop(columns=['source_id', 'rec_id'])

# Display 10 random rows from the df_sample_1_with_recommendations dataframe
recommendation = df_recommendations_fix.sample(10, random_state=0)
recommendation

"""## Evaluation percentage of Cluster in User Data vs Recommendation Data

"""

# Create the count plot
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=df_sample_1, x='cluster', palette='crest')

# Add titles and labels
plt.title('Cluster Percentage in User Data')
plt.xlabel('Cluster')
plt.ylabel('Count')

# Calculate the total number of samples
total = len(df_sample_1)

# Annotate each bar with the count and percentage
for p in ax.patches:
    width = p.get_width()
    height = p.get_height()
    x = p.get_x() + width / 2
    y = p.get_y() + height
    percentage = (height / total) * 100
    ax.annotate(f'{height}\n({percentage:.1f}%)',
                (x, y),
                ha='center',
                va='center',
                xytext=(0, 5),  # vertical offset
                textcoords='offset points')

# Show the plot
plt.show()

# Create the count plot
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=recommendation, x='cluster', palette='crest')

# Add titles and labels
plt.title('Cluster Percentage in Recommendation')
plt.xlabel('Cluster')
plt.ylabel('Count')

# Calculate the total number of samples
total = len(recommendation)

# Annotate each bar with the count and percentage
for p in ax.patches:
    width = p.get_width()
    height = p.get_height()
    x = p.get_x() + width / 2
    y = p.get_y() + height
    percentage = (height / total) * 100
    ax.annotate(f'{height}\n({percentage:.1f}%)',
                (x, y),
                ha='center',
                va='center',
                xytext=(0, 5),  # vertical offset
                textcoords='offset points')

# Show the plot
plt.show()

# Create the box plot
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_sample_1, x='price_fix', palette='light:b')

# Add titles and labels
plt.title('Prices Distribution in User Data')
plt.xlabel('Price')

# Show the plot
plt.show()

# Create the box plot
plt.figure(figsize=(10, 6))
sns.boxplot(data=recommendation, x='price_fix', palette='light:b')

# Add titles and labels
plt.title('Prices Distribution in Recommendation')
plt.xlabel('Price')

# Show the plot
plt.show()

# Calculate counts for each country
country_counts = df_sample_1['country'].value_counts()

# Create the count plot with sorted countries
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=df_sample_1, x='country', order=country_counts.index, palette='crest')

# Add titles and labels
plt.title('Countries in User Data')
plt.xlabel('Countries')
plt.ylabel('Count')

# Calculate the total number of samples
total = len(df_sample_1)

# Annotate each bar with the count and percentage
for p in ax.patches:
    width = p.get_width()
    height = p.get_height()
    x = p.get_x() + width / 2
    y = p.get_y() + height
    percentage = (height / total) * 100
    ax.annotate(f'{height}\n({percentage:.1f}%)',
                (x, y),
                ha='center',
                va='center',
                xytext=(0, 5),  # vertical offset
                textcoords='offset points')

# Show the plot
plt.show()

# Calculate counts for each country
country_counts = recommendation['country'].value_counts()

# Create the count plot with sorted countries
plt.figure(figsize=(10, 6))
ax = sns.countplot(data=recommendation, x='country', order=country_counts.index, palette='crest')

# Add titles and labels
plt.title('Countries in Recommendation')
plt.xlabel('Countries')
plt.ylabel('Count')

# Calculate the total number of samples
total = len(recommendation)

# Annotate each bar with the count and percentage
for p in ax.patches:
    width = p.get_width()
    height = p.get_height()
    x = p.get_x() + width / 2
    y = p.get_y() + height
    percentage = (height / total) * 100
    ax.annotate(f'{height}\n({percentage:.1f}%)',
                (x, y),
                ha='center',
                va='center',
                xytext=(0, 5),  # vertical offset
                textcoords='offset points')

# Show the plot
plt.show()
